# RouteSmith Configuration Example
# Copy this file to routesmith.yaml and customize

# Routing behavior
routing:
  strategy: direct  # direct, cascade, parallel, speculative
  fallback_model: gpt-4o-mini  # Use if no model qualifies

# Budget constraints (optional)
budget:
  max_cost_per_request: 0.10  # USD per request
  max_cost_per_hour: 10.0     # USD per hour
  max_cost_per_day: 100.0     # USD per day
  quality_threshold: 0.8      # Minimum quality score (0-1)

# Semantic cache (optional, requires sentence-transformers)
cache:
  enabled: false
  similarity_threshold: 0.95
  ttl_seconds: 3600

# Feedback collection
feedback:
  enabled: true
  sample_rate: 0.1  # Sample 10% of requests

# Registered models
# Add your models here with their costs and quality scores
models:
  # OpenAI models
  - id: gpt-4o
    cost_per_1k_input: 0.005
    cost_per_1k_output: 0.015
    quality_score: 0.95
    latency_p50_ms: 800
    context_window: 128000

  - id: gpt-4o-mini
    cost_per_1k_input: 0.00015
    cost_per_1k_output: 0.0006
    quality_score: 0.85
    latency_p50_ms: 400
    context_window: 128000

  # Anthropic models
  - id: claude-3-5-sonnet-20241022
    cost_per_1k_input: 0.003
    cost_per_1k_output: 0.015
    quality_score: 0.93
    latency_p50_ms: 600
    context_window: 200000

  - id: claude-3-5-haiku-20241022
    cost_per_1k_input: 0.001
    cost_per_1k_output: 0.005
    quality_score: 0.80
    latency_p50_ms: 300
    context_window: 200000

  # Groq models (fast, free tier available)
  - id: groq/llama-3.1-70b-versatile
    cost_per_1k_input: 0.00059
    cost_per_1k_output: 0.00079
    quality_score: 0.88
    latency_p50_ms: 200
    context_window: 131072

  - id: groq/llama-3.1-8b-instant
    cost_per_1k_input: 0.00005
    cost_per_1k_output: 0.00008
    quality_score: 0.75
    latency_p50_ms: 100
    context_window: 131072
